# MonoVBT: Markerless Velocity Based Training System

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![YOLOv11](https://img.shields.io/badge/YOLO-v11-green)
![MediaPipe](https://img.shields.io/badge/MediaPipe-Pose-orange)
![License](https://img.shields.io/badge/License-MIT-yellow)

[English](#english) | [æ—¥æœ¬èª](#japanese)

<a name="english"></a>

## ğŸ“– English Description

**MonoVBT** is a computer vision-based application for **Velocity Based Training (VBT)** analysis in weightlifting. By combining **YOLOv11** (for robust object detection) and **MediaPipe** (for skeletal pose estimation), it enables high-precision velocity tracking of barbell movements using a single monocular camera (smartphone or webcam).

### Key Features
*   **Hybrid Tracking Engine**: Uses YOLOv11 to crop the athlete's area and MediaPipe for precise joint tracking, robust against complex gym backgrounds.
*   **Grip-Based Calibration**: Auto-calibrates pixel-to-meter scale based on the lifter's grip width (e.g., standard 81cm Ring Mark), eliminating the need for external markers.
*   **Real-time Feedback**: Displays Rep Count, Concentric Velocity, and Fatigue Indicators (Green/Yellow/Red) in real-time.
*   **Scientific Accuracy**: Evaluated against manual frame counting, achieving **MAPE < 10.4%** and **r=0.86** correlation.

![System GUI](assets/images/system_gui_view.png)

### Experimental Results
We verified the accuracy of velocity estimation by comparing it with manual analysis (frame counting) in squat exercises.

| Metric | Value | Description |
| :--- | :--- | :--- |
| **MAE** | **0.024 m/s** | Mean Absolute Error |
| **MAPE** | **10.4 %** | Mean Absolute Percentage Error |
| **Corr (r)** | **0.86** | Correlation Coefficient |

**Velocity Comparison (Repetition vs Velocity)**
![Velocity Plot](assets/images/plot_front_5rep_velocity.png)
*Red: Proposed System, Blue: Manual Ground Truth*

### Installation & Usage
1.  **Install**: `pip install -r requirements.txt`
2.  **Run**: `python tools/launcher_gui.py`

### Technical Architecture
The system employs a **Hybrid Tracking Architecture** ensuring both robustness and precision.

#### 1. Image Processing Pipeline
```mermaid
graph LR
    Input["Video Input"] --> YOLO["YOLOv11 Detection"]
    YOLO -->|"BBox + Margin"| Crop["Dynamic Cropping"]
    Crop --> MP["MediaPipe Pose"]
    MP -->|"Local Landmarks"| Transform["Coord Transformation"]
    Transform -->|"Global Landmarks"| Analyzer["VBT Analyzer"]
```
*   **YOLOv11** detects the athlete's bounding box, handling complex backgrounds.
*   **Dynamic Cropping** extracts the region of interest (ROI) with a safety margin, maximizing image resolution for the pose estimator.
*   **MediaPipe Pose** runs on the cropped image to extract high-precision skeletal coordinate (33 keypoints).

#### 2. Velocity Calculation Logic
Velocity is calculated using the vertical displacement of the barbell (Wrist Keypoints) relative to time.

*   **Grip Calibration ($Scale$)**:
    $$ Scale (m/px) = \frac{Real Grip Width (0.81m)}{Pixel Distance} $$
*   **Instantaneous Velocity ($v_t$)**:
    $$ v_t = \frac{(y_{t-1} - y_t) \times Scale}{\Delta t} $$
    *(Smoothed using a Moving Average Filter to suppress jitter)*

#### 3. Repetition State Machine
Automatic repetition counting is managed by a state machine to prevent false positives.

```mermaid
stateDiagram-v2
    [*] --> WAITING
    WAITING --> ECCENTRIC: Vel < -Threshold
    ECCENTRIC --> CONCENTRIC: Vel > +Threshold
    state CONCENTRIC {
        Recording --> PeakCheck
        PeakCheck --> Displacement
    }
    CONCENTRIC --> WAITING: Vel < ExitThreshold
```

### Constraints & Limitations
*   **Camera Angle**: **Front View Only**. Side views are not supported as the grip width cannot be measured.
*   **Equipment**: Assumes a standard Olympic barbell with 81cm ring marks.
*   **Lighting**: Requires adequate lighting for reliable pose estimation.

---

<a name="japanese"></a>

## ğŸ‡¯ğŸ‡µ æ—¥æœ¬èªè§£èª¬ (Japanese Description)

**MonoVBT**ã¯ã€å˜çœ¼ã‚«ãƒ¡ãƒ©ï¼ˆã‚¹ãƒãƒ›ã‚„Webã‚«ãƒ¡ãƒ©ï¼‰ã ã‘ã§ã‚¦ã‚§ã‚¤ãƒˆãƒªãƒ•ãƒ†ã‚£ãƒ³ã‚°ã®æŒ™ä¸Šé€Ÿåº¦ã‚’è¨ˆæ¸¬ã§ãã‚‹**VBTï¼ˆVelocity Based Trainingï¼‰åˆ†æã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³**ã§ã™ã€‚
å’æ¥­è«–æ–‡ã®ç ”ç©¶æˆæœã¨ã—ã¦é–‹ç™ºã•ã‚Œã€**YOLOv11**ï¼ˆç‰©ä½“æ¤œå‡ºï¼‰ã¨ **MediaPipe**ï¼ˆå§¿å‹¢æ¨å®šï¼‰ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ã‚¸ãƒ ã®ã‚ˆã†ãªè¤‡é›‘ãªèƒŒæ™¯ã§ã‚‚é«˜ç²¾åº¦ãªãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°ã‚’å®Ÿç¾ã—ã¾ã—ãŸã€‚

### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç‰¹å¾´
*   **ãƒãƒ¼ã‚«ãƒ¼ãƒ¬ã‚¹è¨ˆæ¸¬**: ãƒãƒ¼ãƒ™ãƒ«ã‚„èº«ä½“ã«ç‰¹æ®Šãªã‚»ãƒ³ã‚µãƒ¼ãƒ»ãƒãƒ¼ã‚«ãƒ¼ã‚’è£…ç€ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã›ã‚“ã€‚
*   **ã‚°ãƒªãƒƒãƒ—å¹…ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: ãƒªãƒ•ã‚¿ãƒ¼ã®æ‰‹å¹…ï¼ˆ81cmãƒ©ã‚¤ãƒ³ãªã©ï¼‰ã‚’åŸºæº–ã«ç”»ç´ æ•°ã‚’å®Ÿè·é›¢ï¼ˆãƒ¡ãƒ¼ãƒˆãƒ«ï¼‰ã«è‡ªå‹•å¤‰æ›ã™ã‚‹ç‹¬è‡ªãƒ­ã‚¸ãƒƒã‚¯ã‚’æ­è¼‰ã€‚
*   **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯**: ãƒ¬ãƒƒãƒ—æ•°ã€æŒ™ä¸Šé€Ÿåº¦ï¼ˆm/sï¼‰ã€ç–²åŠ´åº¦ï¼ˆé€Ÿåº¦ä½ä¸‹ç‡ï¼‰ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«å¯è¦–åŒ–ã—ã¾ã™ã€‚
*   **é«˜ç²¾åº¦**: æ‰‹å‹•è¨ˆæ¸¬ã¨ã®èª¤å·® 10.4% æœªæº€ã‚’é”æˆã—ã€å¸‚è²©ãƒ‡ãƒã‚¤ã‚¹ã«è¿‘ã„ç²¾åº¦ã‚’å®Ÿè¨¼ã—ã¾ã—ãŸã€‚

![System GUI](assets/images/system_gui_view.png)

### å®Ÿé¨“çµæœ (Experimental Results)
ã‚¹ã‚¯ãƒ¯ãƒƒãƒˆå‹•ä½œã«ãŠã„ã¦ã€æ‰‹å‹•åˆ†æï¼ˆãƒ•ãƒ¬ãƒ¼ãƒ ã‚«ã‚¦ãƒ³ãƒˆæ³•ï¼‰ã¨ã®æ¯”è¼ƒæ¤œè¨¼ã‚’è¡Œã„ã¾ã—ãŸã€‚

| æŒ‡æ¨™ (Metric) | çµæœ (Value) | èª¬æ˜ |
| :--- | :--- | :--- |
| **å¹³å‡çµ¶å¯¾èª¤å·® (MAE)** | **0.024 m/s** | é€Ÿåº¦æ¨å®šã®å¹³å‡çš„ãªã‚ºãƒ¬ |
| **å¹³å‡çµ¶å¯¾èª¤å·®ç‡ (MAPE)** | **10.4 %** | é€Ÿåº¦ã«å¯¾ã™ã‚‹èª¤å·®ã®å‰²åˆ |
| **ç›¸é–¢ä¿‚æ•° (r)** | **0.86** | æ‰‹å‹•è¨ˆæ¸¬ã¨ã®ç›¸é–¢ã®å¼·ã• |

**é€Ÿåº¦æ¨ç§»ã®æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ**
![Velocity Plot](assets/images/plot_front_5rep_velocity.png)
*(èµ¤: æœ¬ã‚·ã‚¹ãƒ†ãƒ , é’: æ‰‹å‹•è¨ˆæ¸¬)*

### æŠ€è¡“çš„ãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
æœ¬ã‚·ã‚¹ãƒ†ãƒ ã¯ã€å …ç‰¢æ€§ã¨ç²¾åº¦ã‚’ä¸¡ç«‹ã•ã›ã‚‹ **ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰è¿½è·¡ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£** ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ã€‚

#### 1. ç”»åƒå‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
```mermaid
graph LR
    Input["æ˜ åƒå…¥åŠ›"] --> YOLO["YOLOv11 ç‰©ä½“æ¤œå‡º"]
    YOLO -->|"BBox + ãƒãƒ¼ã‚¸ãƒ³"| Crop["å‹•çš„ã‚¯ãƒ­ãƒƒãƒ”ãƒ³ã‚°"]
    Crop --> MP["MediaPipe å§¿å‹¢æ¨å®š"]
    MP -->|"ãƒ­ãƒ¼ã‚«ãƒ«åº§æ¨™"| Transform["åº§æ¨™å¤‰æ› (GlobalåŒ–)"]
    Transform -->|"ã‚°ãƒ­ãƒ¼ãƒãƒ«åº§æ¨™"| Analyzer["VBTåˆ†æãƒ­ã‚¸ãƒƒã‚¯"]
```
*   **YOLOv11**: è¤‡é›‘ãªèƒŒæ™¯ã‹ã‚‰ãƒªãƒ•ã‚¿ãƒ¼ã®é ˜åŸŸï¼ˆBounding Boxï¼‰ã‚’å …ç‰¢ã«æ¤œå‡ºã—ã¾ã™ã€‚
*   **å‹•çš„ã‚¯ãƒ­ãƒƒãƒ”ãƒ³ã‚°**: æ¤œå‡ºé ˜åŸŸã«ãƒãƒ¼ã‚¸ãƒ³ã‚’æŒãŸã›ã¦åˆ‡ã‚Šå‡ºã—ã€å§¿å‹¢æ¨å®šå™¨ã¸ã®å…¥åŠ›è§£åƒåº¦ã‚’æœ€å¤§åŒ–ã—ã¾ã™ã€‚
*   **MediaPipe Pose**: åˆ‡ã‚Šå‡ºã•ã‚ŒãŸé«˜è§£åƒåº¦ç”»åƒã«å¯¾ã—ã¦ã€é«˜ç²¾åº¦ãªéª¨æ ¼æ¨å®šï¼ˆ33ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆï¼‰ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

#### 2. é€Ÿåº¦ç®—å‡ºãƒ­ã‚¸ãƒƒã‚¯
ãƒãƒ¼ãƒ™ãƒ«ï¼ˆæ‰‹é¦–ï¼‰ã®å‚ç›´å¤‰ä½ã«åŸºã¥ãã€ç‰©ç†çš„ãªæŒ™ä¸Šé€Ÿåº¦ã‚’ç®—å‡ºã—ã¾ã™ã€‚

*   **ã‚°ãƒªãƒƒãƒ—å¹…ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ ($Scale$)**:
    $$ Scale (m/px) = \frac{\text{å®Ÿã‚°ãƒªãƒƒãƒ—å¹…} (0.81m)}{\text{ç”»ç´ ä¸Šã®æ‰‹å¹…è·é›¢}} $$
*   **ç¬æ™‚é€Ÿåº¦ ($v_t$)**:
    $$ v_t = \frac{(y_{t-1} - y_t) \times Scale}{\Delta t} $$
    *(ã‚¸ãƒƒã‚¿ãƒ¼æŠ‘åˆ¶ã®ãŸã‚ç§»å‹•å¹³å‡ãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨)*

#### 3. ãƒ¬ãƒƒãƒ—æ¤œçŸ¥ã‚¹ãƒ†ãƒ¼ãƒˆãƒã‚·ãƒ³
èª¤æ¤œçŸ¥ï¼ˆFalse Positiveï¼‰ã‚’é˜²ããŸã‚ã€çŠ¶æ…‹é·ç§»ãƒã‚·ãƒ³ã«ã‚ˆã£ã¦ãƒ¬ãƒƒãƒ—ã‚’ç®¡ç†ã—ã¦ã„ã¾ã™ã€‚

```mermaid
stateDiagram-v2
    [*] --> "å¾…æ©Ÿ (WAITING)"
    "å¾…æ©Ÿ (WAITING)" --> "ä¸‹é™ (ECCENTRIC)": é€Ÿåº¦ < -é–¾å€¤
    "ä¸‹é™ (ECCENTRIC)" --> "ä¸Šæ˜‡ (CONCENTRIC)": é€Ÿåº¦ > +é–¾å€¤
    state "ä¸Šæ˜‡ (CONCENTRIC)" {
        ãƒ‡ãƒ¼ã‚¿è¨˜éŒ² --> ãƒ”ãƒ¼ã‚¯é€Ÿåº¦åˆ¤å®š
        ãƒ”ãƒ¼ã‚¯é€Ÿåº¦åˆ¤å®š --> å¤‰ä½é‡ãƒã‚§ãƒƒã‚¯
    }
    "ä¸Šæ˜‡ (CONCENTRIC)" --> "å¾…æ©Ÿ (WAITING)": é€Ÿåº¦ < çµ‚äº†é–¾å€¤
```

### åˆ¶ç´„äº‹é …ãƒ»æ³¨æ„ç‚¹
*   **ã‚«ãƒ¡ãƒ©ã‚¢ãƒ³ã‚°ãƒ«**: **æ­£é¢ï¼ˆFront Viewï¼‰ã®ã¿å¯¾å¿œ**ã—ã¦ã„ã¾ã™ã€‚å´é¢ã‹ã‚‰ã®æ’®å½±ã§ã¯æ‰‹å¹…ãŒè¨ˆæ¸¬ã§ããªã„ãŸã‚ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚
*   **ä½¿ç”¨ãƒãƒ¼ãƒ™ãƒ«**: 81cmãƒ©ã‚¤ãƒ³ï¼ˆãƒªãƒ³ã‚°ãƒãƒ¼ã‚¯ï¼‰ãŒã‚ã‚‹å…¬å¼è¦æ ¼ã®ãƒãƒ¼ãƒ™ãƒ«ã‚’æƒ³å®šã—ã¦ã„ã¾ã™ã€‚
*   **ç’°å¢ƒ**: ååˆ†ãªç…§åº¦ãŒå¿…è¦ã§ã™ã€‚æš—æ‰€ã‚„ã€èƒŒæ™¯ã«äººç‰©ãŒå¯†é›†ã—ã¦ã„ã‚‹ç’°å¢ƒã§ã¯èªè­˜ãŒä¸å®‰å®šã«ãªã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ
ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªã¨ã—ã¦ä»¥ä¸‹ã®æ§‹æˆã«æ•´ç†ã•ã‚Œã¦ã„ã¾ã™ã€‚

*   `src/`: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ï¼ˆYOLO+MediaPipeã®æ¨å®šãƒ­ã‚¸ãƒƒã‚¯ã€GUIæç”»ãªã©ï¼‰
*   `tools/`: ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆGUIãƒ©ãƒ³ãƒãƒ£ãƒ¼ã€ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”¨åˆ†æãƒ„ãƒ¼ãƒ«ï¼‰
*   `thesis/`: å’æ¥­è«–æ–‡ã®åŸç¨¿ï¼ˆLaTeX/Markdownï¼‰ãŠã‚ˆã³å®Ÿé¨“ãƒ‡ãƒ¼ã‚¿ã®å›³è¡¨
*   `experiments/`: ç²¾åº¦æ¤œè¨¼ã«ä½¿ç”¨ã—ãŸå®Ÿé¨“ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨çµæœãƒ‡ãƒ¼ã‚¿
*   `models/`: AIãƒ¢ãƒ‡ãƒ«ï¼ˆYOLOã®é‡ã¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰

### ä½¿ã„æ–¹
1.  **ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«**:
    ```bash
    pip install -r requirements.txt
    ```
2.  **èµ·å‹•**:
    ```bash
    python tools/launcher_gui.py
    ```
    GUIãƒ©ãƒ³ãƒãƒ£ãƒ¼ãŒèµ·å‹•ã—ã¾ã™ã€‚ã€ŒRealtime Analysisã€ï¼ˆWebã‚«ãƒ¡ãƒ©ï¼‰ã¾ãŸã¯ã€ŒAnalyze Videoã€ï¼ˆå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚

### é–‹ç™ºè€…ã«ã¤ã„ã¦
æœ¬ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢ã¯æƒ…å ±ç§‘å­¦ã®å­¦éƒ¨å’æ¥­ç ”ç©¶ã¨ã—ã¦é–‹ç™ºã•ã‚Œã¾ã—ãŸã€‚
