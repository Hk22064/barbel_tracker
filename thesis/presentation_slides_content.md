卒業研究発表資料（スライド構成案 + 台本）
タイトル: 深層学習を用いたマーカーレス・バーベル挙上速度計測システムの構築と評価

発表者: 畠谷佳汰 (5422064)

指導教員: 中原泳青教授

発表時間: 8分 + 質疑応答2分

第1部: スライド構成案
スライド構成（全12-14枚、目安時間配分付き）
1. タイトルスライド（30秒）
タイトル: 深層学習を用いたマーカーレス・バーベル挙上速度計測システムの構築と評価
発表者: 5422064 畠谷佳汰
指導教員: 中原泳青教授
2. 研究背景（1分）
内容:

VBT（Velocity Based Training）とは
挙上速度でトレーニング強度を管理
体調の変動を客観的に把握
既存デバイス（LPT等）の課題
高額（数十万円）
ケーブル接続の手間
フォーム阻害の可能性
既存アプリの課題
アルゴリズム非公開
学術的発展性に乏しい
スライド要素:

VBTの概念図（速度と重量の関係グラフ）
既存デバイス・アプリの写真/スクリーンショット
3. 研究目的（1分）
内容:

目的: スマートフォンの単眼カメラのみを使った、安価で完全非接触なVBTシステムの構築
課題: 単眼カメラでは深さ情報が欠落 → スケールが不定
解決策: ベンチプレスの81cmライン（手幅）を利用したマーカーレス・キャリブレーション
スライド要素:

システム概要図
81cmラインの写真・図解
4. 関連技術（1分）
内容:

姿勢推定アルゴリズムの動向
1. Top-Downアプローチ（YOLOv8-Pose等）
- 人物を検出してからキーポイントを推定する手法
- 人物検出能力は高い
2. Graph-based / Heatmapアプローチ（MediaPipe等）
- 骨格構造の接続関係や時間的な連続性を考慮
- トラッキング機能により滑らかな追跡が可能
先行研究（PSLeon24）
- YOLO + MediaPipe のハイブリッド構成
- 本研究は同手法を**VBT領域へ拡張・応用**
5. 手法選定の根拠（1分）
内容:

予備実験の結果（YOLOv11n vs MediaPipe Pose）
座標推移とノイズ比較
- **YOLO:** フレーム独立性が高いため、静止時でも微細なジッターが観測された
- **MediaPipe:** 内部的なフィルタリング処理により、滑らかな軌跡が得られた
結論
VBTにおいては「**微分の安定性**（ノイズの少なさ）」が最優先
→ **MediaPipeを採用**
6. 提案システム構成（1分）
内容:

ハイブリッドシステムの処理フロー
1. **YOLOv11**で人物領域を初期検出
2. 検出領域を**動的クロッピング**（マージン30%）
3. **MediaPipe Pose**でキーポイント抽出
4. 座標変換して**グローバル座標系**へ
スライド要素:

システムフロー図
実際のシステム画面（図ref{fig:system_view}）
7. マーカーレス・キャリブレーション（1分30秒）
内容:

課題: 単眼カメラではスケール（m/px）が不定
解決策: 81cmライン（手幅）を利用
左右手首間のピクセル距離 = 0.81m
スケール係数 S = 0.81 / 手首間距離
指幅補正（約2cm×2）も実装
利点: 外部マーカー不要、即座に計測開始可能
スライド要素:

キャリブレーションの概念図
計算式の提示
Before/After（スケール補正前後）の比較
8. 速度算出と平滑化（1分）
内容:

速度算出手順:
瞬時速度 = (前フレーム座標 - 現フレーム座標) × S / Δt
移動平均フィルタ（Window=5）で平滑化
ステートマシンによる動作解析:
WAITING → ECCENTRIC（下降） → CONCENTRIC（挙上）
ピーク速度・平均速度を記録
スライド要素:

速度算出の数式
ステートマシンの状態遷移図
9. 実験①設定：レップ検出（30秒）
内容:

実験方法:
アングル（撮影角度）の異なる動画に対し、各手法でレップカウントを実施し、正解数に対する一致を検証
比較条件:
1. Proposed (Hybrid): YOLO + MediaPipe（提案手法）
2. Comparison A: YOLOv11x（検出ベースのSOTA）
※各手法に対し、横アングル(条件A)と縦アングル(条件B)で評価
評価指標:
レップ検出率 (Detection Rate)
アングル別ロバスト性 (Robustness)
スライド要素:

実験方法の概要
条件と指標のリスト
撮影条件の写真（横 vs 縦）
10. 実験結果①（レップ検出率）（1分）
内容:

提案手法 vs YOLO11x の比較:
横撮り・正面: 提案手法 100%, YOLO 89%
縦撮り・遠距離: 提案手法 100%, YOLO 30% ← 圧倒的な優位性
課題: サイドビュー（左右）ではオクルージョンにより精度低下
スライド要素:

レップ検出率の比較表
成功例と失敗例の画像
11. 実験②設定：速度推定精度（30秒）
内容:

実験方法:
提案システムが算出した速度（System Vel）と、手作業によるフレームカウントから算出した基準値（Manual Vel）を比較検証
比較条件:
Condition A (横・正面): 理想的な環境での精度
Condition B (縦・遠距離): 解像度が低い環境での精度
Condition C (疲労時): 速度低下時の追従性
評価指標:
MAE (平均絶対誤差)
MAPE (平均絶対パーセント誤差)
相関係数 (Correlation Coefficient)
スライド要素:

実験フロー図（System vs Manual）
評価指標のリスト
12. 実験結果②（速度推定精度）（1分）
内容:

速度推定精度の全体サマリ

| 指標 | 全体平均 | 評価 |
|------|----------|------|
| **MAE** | 0.024 m/s | -- |
| **MAPE** | **10.4%** | 市販アプリ(誤差約10%)と同等水準（参考値） |
| **相関係数** | **r=0.86** | パフォーマンス変動を捉えている |

結果の分析（考察）:
1. **安定性:** 中重量(front_5rep)ではMAPE 4.6%と非常に高い精度を達成
2. **疲労検知:** 挙上速度低下時(front_9rep)も誤差5%未満で追従可能 → **限界判定に有効**
3. **課題:** 遠距離(front_10rep)では解像度不足による量子化誤差の影響が見られた

条件別の結果
- **front_5rep:** MAPE 4.6%（安定）
- **front_9rep:** MAPE 11.4%（疲労時も高精度）
- **front_10rep:** MAPE 15.1%（遠距離で若干低下）

※ 基準値（v_manual）は実測距離とフレーム数から算出
スライド要素:

速度推定精度のサマリ表
速度比較グラフ（System Vel vs Manual Vel）
12. 考察（1分）
内容:

ロバスト性向上の要因:
ハイブリッド追跡（YOLO初期検出 + MediaPipe追跡）
パラメータ最適化（移動平均5フレーム）
限界と今後の課題:
遠距離撮影時の解像度不足
超解像技術や高度なフィルタ（カルマンフィルタ等）の導入
81cmラインが見えない環境での精度検証
スライド要素:

ロバスト性の要因を箇条書き
課題と今後の展望
13. 結論（30秒）
内容:

MediaPipeを用いたマーカーレスVBTシステムを構築・評価
縦撮り・見切れ環境でも安定した計測が可能
結論: 「MediaPipeによる高速な姿勢推定」 + 「手首間距離を利用したマーカーレス自動キャリブレーション」が有効なアプローチ
今後の展望: スクワット・デッドリフトへの適用、音声フィードバック機能の実装、骨格情報を活用した「フォーム評価」への拡張
スライド要素:

研究成果のまとめ（箇条書き）
今後の展望
14. 参考文献 / 謝辞（省略可）
内容:

主要な参考文献のリスト
指導教員への謝辞
補足・推奨事項
タイムマネジメント:
各スライドの目安時間を守る
特に「提案手法」「実験結果」に時間を割く
時間が足りない場合は「関連技術」や「実験設定」を簡略化
スライドデザイン:
シンプルで読みやすいデザイン
図表は大きく、文字は最小限に
重要な数値（MAPE 10.4%, r=0.86等）は強調表示
第2部: 発表台本
【スライド1: タイトル】（30秒）
こんにちは。畠谷です。
本日は、「深層学習を用いたマーカーレス・バーベル挙上速度計測システムの構築と評価」について発表します。
よろしくお願いします。

【スライド2: 研究背景】（1分）
まず、研究の背景です。

近年、筋トレの現場では、重さだけでなく、速度を指標にトレーニングを管理する、VBT（Velocity Based Training）という手法が注目されています。

速度を測ることで、その日の体調を客観的に把握でき、効果的な負荷設定が可能になります。

しかし、既存のVBTデバイスには、いくつか課題があります。
まず、価格が高い。数十万円します。
次に、バーベルにケーブルを取り付ける手間がかかる。
さらに、ケーブルがフォームを邪魔する可能性もあります。

また、スマホアプリも登場していますが、アルゴリズムが非公開で、学術的な発展性に乏しいという課題があります。

【スライド3: 研究目的】（1分）
そこで本研究では、スマホの単眼カメラだけを使った、安価で完全非接触なVBTシステムの構築を目指しました。

単眼カメラでは、深さ情報が欠けるため、スケールが不定という課題があります。

この課題に対し、ベンチプレスの標準規格である、81センチライン、つまり手幅のラインを利用します。
これにより、外部マーカーなしで、絶対速度を推定できるようにしました。

【スライド4: 関連技術】（1分）
次に、関連技術です。

姿勢推定には、主に2つのアプローチがあります。

1つ目は、YOLOなどのTop-Down方式。
人物を検出してから、キーポイントを推定します。

2つ目は、MediaPipe BlazePoseです。
こちらは、トラッキング機能により、滑らかな追跡が可能です。

また、先行研究では、YOLOとMediaPipeを組み合わせたハイブリッド構成が、姿勢フィードバックに使われています。
本研究は、この手法をVBT領域へ拡張したものです。

【スライド5: 手法選定の根拠】（1分）
どちらのアルゴリズムが適しているか、予備実験を行いました。

YOLOは、フレームごとに独立して検出するため、ジッターが大きくなります。
一方、MediaPipeは、時系列フィルタリングにより、滑らかな軌跡が得られます。

VBTでは、速度を微分で計算するため、ノイズの少なさが最重要です。
そのため、本研究ではMediaPipeを採用しました。

【スライド6: 提案システム構成】（1分）
提案システムの構成です。

まず、YOLOで人物領域を初期検出します。
次に、その領域を少し広げて切り出します。マージンは30パーセントです。
そして、切り出した高解像度画像に対して、MediaPipeでキーポイントを抽出します。
最後に、座標をグローバル座標系に変換します。

この流れにより、安定した追跡が可能になります。

【スライド7: マーカーレス・キャリブレーション】（1分30秒）
次に、マーカーレス・キャリブレーションです。

単眼カメラでは、1ピクセルが何メートルに相当するか、が不定です。

これを解決するため、81センチラインを利用します。
具体的には、左右の手首間のピクセル距離を、実際の0.81メートルに対応させます。

計算式は、スケール係数Sイコール、0.81割る手首間距離、です。

さらに、指幅の違いも考慮した補正機能を実装しました。
例えば、人差し指をラインに掛ける場合は、約4センチを加算します。

これにより、外部マーカーなしで、即座に計測を開始できます。

【スライド8: 速度算出と平滑化】（1分）
速度の算出方法です。

まず、瞬時速度を計算します。
式は、前フレームの座標マイナス現フレームの座標、かけるスケール係数、割るフレーム間隔、です。

次に、移動平均フィルタで平滑化します。ウィンドウサイズは5フレームです。

また、ステートマシンで動作を解析します。
待機→下降→挙上、という状態遷移により、レップを自動検知します。

【スライド9: 実験設定】（30秒）
実験設定です。

環境は、Windows 11、CPUでMediaPipe、GPUでYOLOを動かしました。

撮影条件は2つです。
条件Aは、横アングルの理想環境。
条件Bは、スマホ縦持ちの厳しい環境です。

評価指標は、レップ検出率と、速度推定精度です。

【スライド10: 実験結果① レップ検出率】（1分）
実験結果です。

まず、レップ検出率です。

横撮り・正面では、提案手法が100パーセント、YOLOが89パーセントでした。

注目すべきは、縦撮り・遠距離の条件です。
提案手法は100パーセント検出できましたが、YOLOは30パーセントしか検出できませんでした。

これは、ハイブリッド追跡の効果が大きく表れた結果です。

一方、サイドビューでは、プレートによる隠れの影響で、精度が低下しました。

【スライド11: 実験結果② 速度推定精度】（1分）
次に、速度推定精度です。

全体平均で、MAEは0.024メートル毎秒、
MAPEは10.4パーセント、
相関係数は0.86でした。

MAPEの10.4パーセントは、市販デバイスの許容誤差内です。
また、相関係数0.86は、高い相関を示しています。

条件別では、中重量で安定したフォームの場合、MAPEは4.6パーセントと非常に高精度でした。
疲労時や遠距離でも、概ね良好な精度を維持できました。

【スライド12: 考察】（1分）
考察です。

ロバスト性が向上した要因は、2つあります。

1つ目は、ハイブリッド追跡です。
YOLOの初期検出と、MediaPipeの追跡を組み合わせることで、検出の飛びを抑制できました。

2つ目は、パラメータ最適化です。
移動平均を5フレームに設定したことで、ノイズを除去しつつ、急激な速度変化にも追従できました。

一方、限界もあります。
遠距離撮影では、解像度不足により精度が低下しました。

今後は、超解像技術や、カルマンフィルタの導入を検討します。
また、81センチラインが見えない環境での精度検証も必要です。

【スライド13: 結論】（30秒）
結論です。

本研究では、MediaPipeを用いたマーカーレスVBTシステムを構築し、評価しました。

縦撮りや見切れがある環境でも、安定した計測が可能であることを示しました。

MediaPipeによる高速な姿勢推定と、手首間距離を利用したマーカーレス・キャリブレーションの組み合わせが、有効なアプローチであると結論付けます。

今後は、スクワットやデッドリフトへの適用、音声フィードバック機能の実装を目指します。

以上で発表を終わります。ご清聴ありがとうございました。

第3部: 質疑応答対策
想定質問1: YOLOとMediaPipeのハイブリッドにした理由は?
回答例:
YOLOは検出能力が高いですが、フレームごとに独立して検出するため、ジッターが大きくなります。一方、MediaPipeは時系列フィルタリングにより滑らかな軌跡が得られます。そのため、YOLOで初期位置を特定し、その後はMediaPipeで追跡することで、両者の長所を活かすことができます。

想定質問2: 81cmラインが見えない場合はどうするのか?
回答例:
現状のシステムでは、81センチラインが基準となっているため、見えない場合は精度が低下する可能性があります。今後の課題として、ユーザーが手動でスケールを入力できる機能や、他の既知の物体（例えばプレートのサイズ）を利用したキャリブレーション手法の導入を検討しています。

想定質問3: 他の種目（スクワット等）への適用可能性は?
回答例:
スクワットやデッドリフトへの適用は十分可能だと考えています。ただし、キャリブレーションの基準点が異なるため、例えばスクワットであれば肩幅、デッドリフトであればプレートの直径など、別の既知のサイズを利用する必要があります。また、動作のステートマシンも種目ごとに調整が必要です。

想定質問4: 市販アプリとの精度比較はしたのか?
回答例:
今回の研究では、基準値として手動で計測した速度を用いており、市販アプリとの直接比較は行っていません。ただし、先行研究では市販アプリがLPTと同等の精度（相関係数0.90以上）であることが報告されており、本システムの相関係数0.86も実用レベルに近い値です。今後、市販デバイスとの比較実験を行いたいと考えています。

第4部: 噛み対策・読み方のコツ
短文で区切る
長い文章は、句読点で必ず一呼吸置く
特に数値や専門用語の前後は、ゆっくり話す
難しい単語の読み方確認
VBT: ブイビーティー
MediaPipe: メディアパイプ
YOLO: ヨーロー
MAPE: マップイー（またはエムエーピーイー）
MAE: エムエーイー
ジッター: ジッター（jitter）
オクルージョン: オクルージョン（隠れ）
ゆっくり話す
早口にならないよう、意識的にゆっくり話す
特に数値（0.81m、10.4%等）は、確実に伝わるように
リハーサル
実際に声に出して練習する（最低3回以上）
スマホで録音して聞き返す
噛みやすい箇所はメモしておき、言い換えを検討
当日の心構え
深呼吸をして落ち着く
噛んでしまっても、焦らず言い直す
スライドを指差しながら話すと、落ち着きやすい